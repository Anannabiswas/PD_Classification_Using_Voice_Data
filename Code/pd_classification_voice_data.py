# -*- coding: utf-8 -*-
"""PD_Classification_Voice_Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FsR5ja4c2he7KrbblBytCbQE7NI7BjMs

#Import Necessary Libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, precision_recall_curve, auc
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline

"""#Loading the dataset"""

# Load the dataset
file_path = '/content/parkinsons.data'  # Update with actual file path in Colab
df = pd.read_csv(file_path)

"""#Visualizing the basic info of the dataset"""

# Display basic info
display(df.head())
display(df.info())

"""### Checking the shape of the data"""

print(df.shape)

"""#1. PD Classification using ML (Random Forest, SVM and KNN) model with SMOTE Technique

#Preprocessing the data
"""

# Drop the 'name' column as it's not useful for classification
df = df.drop(columns=['name'])

"""### Correlation Analysis"""

print(df.shape)

# Compute and display correlation matrix
plt.figure(figsize=(12,10))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title("Feature Correlation Matrix")
plt.show()

"""
### We plot the correlation between features and with the target (status) to understand which features are important.
"""

# Compute and display correlation matrix for 'status'
plt.figure(figsize=(8,10))
corr_with_status = df.corr()["status"].drop("status").sort_values(ascending=False)
sns.heatmap(corr_with_status.to_frame(), annot=True, cmap='coolwarm', fmt='.1f', linewidths=0.2)
plt.title("Correlation of Features with Status")
plt.show()

"""###Define features and target variable"""

# Define features and target variable
X = df.drop(columns=['status'])
y = df['status']

"""###Splitting data into train and test set
We split the dataset into training and testing subsets while keeping class distribution equal using stratify=y.
"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""###Since models like SVM and KNN are sensitive to feature scales, we apply standardization (mean=0, std=1)."""

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""###Plotting class distribution of the unbalanced data"""

# Plot class distribution before SMOTE
sns.countplot(x=y_train)
plt.title("Class Distribution Before SMOTE")
plt.show()

"""### Applying SMOTE Technique for balancing the class distribution
SMOTE (Synthetic Minority Over-sampling Technique) generates synthetic examples of the minority class to create a balanced training set.
"""

# Apply SMOTE to balance the dataset
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

"""### Plotting the balanced dataset using SMOTE"""

# Display class distribution before and after SMOTE
print("Class distribution before SMOTE:")
print(y_train.value_counts())
print("Class distribution after SMOTE:")
print(pd.Series(y_train_balanced).value_counts())

# Plot class distribution
sns.countplot(x=y_train_balanced)
plt.title("Class Distribution After SMOTE")
plt.show()

"""#Initializing Classifier with their Parameters
Weâ€™ll train three different classifiers:

Random Forest: Tree-based ensemble model.

K-Nearest Neighbors (KNN): Classifies based on nearby points.

Support Vector Machine (SVM): Finds the best hyperplane to separate classes.
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Initialize the classifiers
rf_clf = RandomForestClassifier(random_state=42)
knn_clf = KNeighborsClassifier()
svm_clf = SVC(random_state=42)

"""### Traning and Evaluating Random Forest"""

# Train and evaluate Random Forest
rf_clf.fit(X_train_balanced, y_train_balanced)
rf_preds = rf_clf.predict(X_test_scaled)
print("Random Forest Classifier Results:")
print("Accuracy:", accuracy_score(y_test, rf_preds))
print("Confusion Matrix:\n", confusion_matrix(y_test, rf_preds))
print("Classification Report:\n", classification_report(y_test, rf_preds))

"""### Traning and Evaluating KNN"""

# Train and evaluate KNN
knn_clf.fit(X_train_balanced, y_train_balanced)
knn_preds = knn_clf.predict(X_test_scaled)
print("K-Nearest Neighbors Classifier Results:")
print("Accuracy:", accuracy_score(y_test, knn_preds))
print("Confusion Matrix:\n", confusion_matrix(y_test, knn_preds))
print("Classification Report:\n", classification_report(y_test, knn_preds))

"""### Traning and Evaluating SVM"""

# Train and evaluate SVM
svm_clf.fit(X_train_balanced, y_train_balanced)
svm_preds = svm_clf.predict(X_test_scaled)
print("Support Vector Machine Classifier Results:")
print("Accuracy:", accuracy_score(y_test, svm_preds))
print("Confusion Matrix:\n", confusion_matrix(y_test, svm_preds))
print("Classification Report:\n", classification_report(y_test, svm_preds))

"""#Visualizing Model Performance"""

from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix, ConfusionMatrixDisplay

# Helper function to evaluate a model
def evaluate_model(model, X_test, y_test, model_name):
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)  # Sensitivity
    f1 = f1_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)

    print(f"\n{model_name} Results:")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Sensitivity (Recall): {rec:.4f}")
    print(f"F1 Score: {f1:.4f}")

    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
    disp.plot(cmap='Blues')
    plt.title(f"{model_name} - Confusion Matrix")
    plt.show()

# Random Forest
rf_clf.fit(X_train_balanced, y_train_balanced)
evaluate_model(rf_clf, X_test_scaled, y_test, "Random Forest")

# KNN
knn_clf.fit(X_train_balanced, y_train_balanced)
evaluate_model(knn_clf, X_test_scaled, y_test, "K-Nearest Neighbors")

# SVM
svm_clf.fit(X_train_balanced, y_train_balanced)
evaluate_model(svm_clf, X_test_scaled, y_test, "Support Vector Machine")

"""###Comparing the ROC curves
Receiver Operating Characteristic (ROC) curves show the trade-off between true positive rate and false positive rate.
"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, RocCurveDisplay

plt.figure(figsize=(8, 6))

# Models to compare (trained on SMOTE-balanced data)
models = {
    "Random Forest": rf_clf,
    "KNN": knn_clf,
    "SVM": svm_clf
}

# Store ROC data for legend modification
roc_data = {}

for name, model in models.items():
    # Get prediction scores
    if hasattr(model, "predict_proba"):
        y_score = model.predict_proba(X_test_scaled)[:, 1]
    else:
        y_score = model.decision_function(X_test_scaled)

    # Compute ROC and plot
    fpr, tpr, _ = roc_curve(y_test, y_score)
    roc_auc = auc(fpr, tpr)
    roc_data[name] = (fpr, tpr, roc_auc)
    RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=name).plot(ax=plt.gca())

# Plot random chance line
plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.5)')

# Get current legend items
handles, labels = plt.gca().get_legend_handles_labels()

# Modify labels to include AUC (only for models, not the random line)
new_labels = []
for label in labels:
    if label in roc_data:
        new_labels.append(f"{label} (AUC={roc_data[label][2]:.2f})")
    else:
        new_labels.append(label)

# Apply the modified legend
plt.legend(handles, new_labels, loc="lower right")

plt.title("ROC Curves - SMOTE without RFE")
plt.grid()
plt.show()

"""###Comparing of Precision-Recall Curve

#2. PD Classification using ML (Random Forest, SVM, and KNN) with RFE-based Feature Selection and SMOTE Technique

#Preprocessing the Data

### Splitting the data into train and test set
"""

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

"""#Feature Selection using Recursive Feature Elimination (RFE)"""

# Define base estimator for RFE
base_estimator = RandomForestClassifier(random_state=42, n_estimators=100)

# Define classifiers and their hyperparameters
classifiers = {
    'Random Forest': {
        'model': RandomForestClassifier(random_state=42),
        'params': {
            'model__n_estimators': [100, 200],
            'model__max_depth': [None, 10, 20]
        },
        'use_scaler': False,
        'feature_selector': RFE(estimator=base_estimator, n_features_to_select=10)
    },
    'SVM': {
        'model': SVC(random_state=42, class_weight='balanced', probability=True),
        'params': {
            'model__C': [0.1, 1, 10],
            'model__kernel': ['rbf', 'linear'],
            'model__gamma': ['scale', 'auto']
        },
        'use_scaler': True,
        'feature_selector': RFE(estimator=base_estimator, n_features_to_select=10)
    },
    'KNN': {
        'model': KNeighborsClassifier(),
        'params': {
            'model__n_neighbors': [3, 5, 7]
        },
        'use_scaler': True,
        'feature_selector': RFE(estimator=base_estimator, n_features_to_select=10)
    }
}

"""#Visualizing most important features for random forest"""

# 1. Define base estimator and fit RFE
base_estimator = RandomForestClassifier(random_state=42, n_estimators=100)
rfe_selector = RFE(estimator=base_estimator, n_features_to_select=10)
rfe_selector.fit(X, y)

# 2. Extract feature importances from fitted internal estimator
importances = rfe_selector.estimator_.feature_importances_
selected_features = X.columns[rfe_selector.support_]

# 3. Sort features by importance
sorted_idx = np.argsort(importances)[::-1]
sorted_features = selected_features[sorted_idx]
sorted_importances = importances[sorted_idx]

# 4. Plot
plt.figure(figsize=(10, 6))
plt.barh(sorted_features, sorted_importances, color='teal')
plt.xlabel('Feature Importance')
plt.title('Top 10 Selected Feature Importances (RFE + Random Forest)')
plt.gca().invert_yaxis()
plt.grid(True, linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

"""#Model Training and Evaluation

###Random Forest with RFE and SMOTE
"""

# Train Random Forest
print("Training: Random Forest")

rf_steps = [
    ('smote', SMOTE(random_state=42)),
    ('feature_selection', RFE(estimator=RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=10)),
    ('model', RandomForestClassifier(random_state=42))
]
rf_pipeline = ImbPipeline(steps=rf_steps)

rf_params = {
    'model__n_estimators': [100, 200],
    'model__max_depth': [None, 10, 20]
}

rf_grid = GridSearchCV(rf_pipeline, param_grid=rf_params, cv=5, scoring='accuracy', n_jobs=-1)
rf_grid.fit(X_train, y_train)
best_model_rf = rf_grid.best_estimator_
y_pred_rf = best_model_rf.predict(X_test)

print("Best Parameters (RF):", rf_grid.best_params_)
print("Confusion Matrix (RF):\n", confusion_matrix(y_test, y_pred_rf))
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print("Classification Report (RF):\n", classification_report(y_test, y_pred_rf, digits=4))

"""### Support Vector Machine (SVM) with RFE and SMOTE"""

# Train SVM
print("\nTraining: SVM")

svm_steps = [
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=42)),
    ('feature_selection', RFE(estimator=RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=10)),
    ('model', SVC(random_state=42, class_weight='balanced', probability=True))
]
svm_pipeline = ImbPipeline(steps=svm_steps)

svm_params = {
    'model__C': [0.1, 1, 10],
    'model__kernel': ['rbf', 'linear'],
    'model__gamma': ['scale', 'auto']
}

svm_grid = GridSearchCV(svm_pipeline, param_grid=svm_params, cv=5, scoring='accuracy', n_jobs=-1)
svm_grid.fit(X_train, y_train)
best_model_svm = svm_grid.best_estimator_
y_pred_svm = best_model_svm.predict(X_test)

print("Best Parameters (SVM):", svm_grid.best_params_)
print("Confusion Matrix (SVM):\n", confusion_matrix(y_test, y_pred_svm))
print(f"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}")
print("Classification Report (SVM):\n", classification_report(y_test, y_pred_svm, digits=4))

"""###K-Nearest Neighbors (KNN) with RFE and SMOTE"""

# Train KNN
print("\nTraining: KNN")

knn_steps = [
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=42)),
    ('feature_selection', RFE(estimator=RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=10)),
    ('model', KNeighborsClassifier())
]
knn_pipeline = ImbPipeline(steps=knn_steps)

knn_params = {
    'model__n_neighbors': [ 7]
}

knn_grid = GridSearchCV(knn_pipeline, param_grid=knn_params, cv=5, scoring='accuracy', n_jobs=-1)
knn_grid.fit(X_train, y_train)
best_model_knn = knn_grid.best_estimator_
y_pred_knn = best_model_knn.predict(X_test)

print("Best Parameters (KNN):", knn_grid.best_params_)
print("Confusion Matrix (KNN):\n", confusion_matrix(y_test, y_pred_knn))
print(f"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}")
print("Classification Report (KNN):\n", classification_report(y_test, y_pred_knn, digits=4))

"""#Model Performance Evaluation

### Plotting Confusion Matrix

###Random Forest
"""

# Plot confusion matrix
plt.figure(figsize=(4, 3))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues', xticklabels=['Healthy', 'PD'], yticklabels=['Healthy', 'PD'])
plt.title('Confusion Matrix - Random Forest with RFE')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

"""###SVM Model"""

# Plot confusion matrix
plt.figure(figsize=(4, 3))
sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', cmap='Blues', xticklabels=['Healthy', 'PD'], yticklabels=['Healthy', 'PD'])
plt.title('Confusion Matrix - SVM with RFE')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

"""###KNN Classifier"""

# Plot confusion matrix
plt.figure(figsize=(4, 3))
sns.heatmap(confusion_matrix(y_test, y_pred_knn), annot=True, fmt='d', cmap='Blues', xticklabels=['Healthy', 'PD'], yticklabels=['Healthy', 'PD'])
plt.title('Confusion Matrix - KNN with RFE')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

"""#Plotting ROC Curve"""

# Combined ROC Curve
plt.figure(figsize=(8, 6))

models = {
    'Random Forest': best_model_rf,
    'SVM': best_model_svm,
    'KNN': best_model_knn
}

for name, model in models.items():
    if hasattr(model, "predict_proba"):
        y_score = model.predict_proba(X_test)[:, 1]
    else:
        y_score = model.decision_function(X_test)

    fpr, tpr, _ = roc_curve(y_test, y_score)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC CurveS - SMOTE with RFE')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()